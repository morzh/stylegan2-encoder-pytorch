{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import dist_model as dm\n",
    "from data import data_loader as dl\n",
    "import argparse\n",
    "from IPython import embed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from data.twoafc_dataset import TwoAFCDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "datasets = ['val/traditional','val/cnn','val/superres','val/deblur','val/color','val/frameinterp']\n",
    "dataset_mode = '2afc' # 2afc or jnd\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional Baselines\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L1',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'L1 [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L2',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'L2 [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='ssim',colorspace='Gray',use_gpu=is_cuda)\n",
    "m.model_name = 'SSIM [LA]'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson models\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_watson_dct_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='dct', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-dct [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_watson_fft_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='fft', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-fft [LA]'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeploss competitor: lin tuned vgg\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_pnet_lin_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='vgg', model_path=path, colorspace='Gray',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-vgg [LA]'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./checkpoints/gray_pnet_lin_squeeze_trial0/latest_net_.pth\n"
     ]
    }
   ],
   "source": [
    "# Deeploss competitor 2: lin tuned squeezenet\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_pnet_lin_squeeze_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='squeeze', model_path=path, colorspace='Gray',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-squeeze [LA]'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional Baselines\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L1',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'L1'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='L2',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'L2'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "m.initialize(model='ssim',colorspace='RGB',use_gpu=is_cuda)\n",
    "m.model_name = 'SSIM'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson models\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_watson_dct_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='dct', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-dct'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_watson_fft_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='watson', net='fft', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path))\n",
    "m.model_name = 'Watson-fft'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeploss competitor: lin tuned vgg\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_pnet_lin_vgg_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='vgg', model_path=path, colorspace='RGB',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-vgg'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./checkpoints/rgb_pnet_lin_squeeze_trial0/latest_net_.pth\n"
     ]
    }
   ],
   "source": [
    "# Deeploss competitor 2: lin tuned squeeze\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_pnet_lin_squeeze_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='net-lin', net='squeeze', model_path=path, colorspace='RGB',use_gpu=is_cuda, batch_size=64)\n",
    "m.model_name = 'Deeploss-squeeze'\n",
    "m.batch_size = m.batch_size // 4\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive loss, as per reviewer request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'gray_adaptive_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='adaptive', colorspace='Gray',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path, map_location=device))\n",
    "m.model_name = 'Adaptive [LA]'\n",
    "models.append(m)\n",
    "\n",
    "m = dm.DistModel()\n",
    "path=os.path.join('./checkpoints/', 'rgb_adaptive_trial0', 'latest_net_.pth')\n",
    "m.initialize(model='adaptive', colorspace='RGB',use_gpu=is_cuda)\n",
    "m.net.load_state_dict(torch.load(path, map_location=device))\n",
    "m.model_name = 'Adaptive'\n",
    "models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddict(d):\n",
    "    return defaultdict(lambda: defaultdict(lambda: {}), d)\n",
    "\n",
    "def ddict2dict(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = ddict2dict(v)\n",
    "    return dict(d)\n",
    "\n",
    "def dict2ddict(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            d[k] = dict2ddict(v)\n",
    "    return ddict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data loader\n",
    "def eval_loss_metric(model, resultdict=None):\n",
    "    if resultdict is None:\n",
    "        resultdict = defaultdict(lambda: defaultdict(lambda: {}))\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        data_loader = dl.CreateDataLoader(dataset, dataset_mode=dataset_mode, batch_size=model.batch_size)\n",
    "\n",
    "        # evaluate model on data\n",
    "        if(dataset_mode=='2afc'):\n",
    "            (score, results_verbose) = dm.score_2afc_dataset(data_loader, model.forward)\n",
    "            resultdict[model.model_name][dataset]['score'] = results_verbose['scores'].mean()\n",
    "            resultdict[model.model_name][dataset]['std'] = results_verbose['scores'].std()\n",
    "            \n",
    "            human_judgements = results_verbose['gts']\n",
    "            human_scores = human_judgements**2 + (1 - human_judgements)**2\n",
    "            resultdict['Human'][dataset]['score'] = human_scores.mean()\n",
    "            resultdict['Human'][dataset]['std'] = human_scores.std()\n",
    "            \n",
    "            \n",
    "        elif(dataset_mode=='jnd'):\n",
    "            raise Exception('not implemented / validated')\n",
    "            (score, results_verbose) = dm.score_jnd_dataset(data_loader, model.forward)\n",
    "\n",
    "\n",
    "        # print results\n",
    "        print(' Model [%s]  Dataset [%s]: %.2f'%(model.model_name, dataset, 100.*score))\n",
    "    return resultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval model 1 / 2: \"Adaptive [LA]\"\n"
     ]
    }
   ],
   "source": [
    "res = dict2ddict(pickle.load(open(\"eval_results.p\", \"rb\")))\n",
    "#res = defaultdict(lambda: defaultdict(lambda: {}))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print('eval model {} / {}: \"{}\"'.format(i+1, len(models), model.model_name))\n",
    "    eval_loss_metric(model, res)\n",
    "\n",
    "# save results\n",
    "pickle.dump(ddict2dict(res), open(\"eval_results.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
